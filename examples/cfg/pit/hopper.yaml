params:  
  diff_env:
    name: HopperEnv
    stochastic_env: True
    episode_length: 1000
    MM_caching_frequency: 16

  network:
    actor: ActorStochasticMLP
    actor_mlp:
      units: [128, 64, 32]
      activation: elu

    critic: CriticMLP
    critic_mlp:
      units: [64, 64]
      activation: elu

  config:
    name: df_hopper_pit
    actor_learning_rate: 1e-3 # adam
    critic_learning_rate: 5e-4 # adam
    lr_schedule: linear # ['constant', 'linear']
    target_critic_alpha: 0.2 
    obs_rms: True
    ret_rms: False
    critic_iterations: 16
    critic_method: td-lambda
    lambda: 0.95
    num_batch: 4
    gamma: 0.99
    betas: [0.7, 0.95] # adam
    
    grad_norm: 1.0 
    truncate_grads: True
    num_actors: 64
    save_interval: 400
    max_epochs: 2000
    ppo_clip: 0.0
    steps_num: 32
    actor_iterations: 8
    horizon: 32
    num_minibatches: 1

    player:
      determenistic: False
      games_num: 1
      num_actors: 1
      print_stats: True
